# DEPRECATED
version: '3'

tasks: 
  init:
    requires:
      vars: 
        - DB_TYPE
        - DB_ALIAS
        - GCS_BUCKET
    vars:
      GCS_SUBPATH: '{{ .DB_TYPE }}/{{ .DB_ALIAS }}'
    cmds:
      - |
        if [[ -f "${GCS_CREDENTIALS_FILE}" ]]; then
          gcloud auth login --cred-file=$GCS_CREDENTIALS_FILE
        fi
      - echo "GCS Storage initialized for bucket '{{ .GCS_BUCKET }}'."

  upload:
    requires:
      vars: 
        - BACKUP_DIR
        - DB_TYPE
        - DB_ALIAS
    vars:
      GCS_SUBPATH: '{{ .DB_TYPE }}/{{ .DB_ALIAS }}'
    cmds: 
      - gcloud storage cp -r {{ .BACKUP_DIR }}/* gs://{{ .GCS_BUCKET }}/{{ .GCS_SUBPATH }}/$(basename {{ .BACKUP_DIR }})/
  clean:
    requries:
      vars: 
        - DB_TYPE
        - DB_ALIAS
        - RETENTION_DAYS
    vars: 
      GCS_SUBPATH: '{{ .DB_TYPE }}/{{ .DB_ALIAS }}'
      DATE_THRESHOLD:
        sh: date --date='{{ .RETENTION_DAYS }} days ago' +'%Y-%m-%dT%H:%M:%S'
    cmds: 
      - |
        for obj in $(gcloud storage objects list gs://{{ .GCS_BUCKET }}/{{ .GCS_SUBPATH }}/** --raw --filter "timeFinalized<'{{ .DATE_THRESHOLD }}'" --format="list(name)" | sed 's/ - //g'); do
          gcloud storage rm gs://{{ .GCS_BUCKET }}/$obj
        done